{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "378df312",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\debdi\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b40462c",
   "metadata": {},
   "source": [
    "## We will be taking X's as 1 and O's as -1 and by default empty is zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d26f5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicTacToeEnv:\n",
    "    def __init__(self):\n",
    "        self.board = np.zeros((3, 3), dtype=int)\n",
    "        self.current_player = 1\n",
    "        \n",
    "    def reset(self):\n",
    "        self.board[:] = 0\n",
    "        self.current_player = 1\n",
    "        return self.get_state()\n",
    "    \n",
    "    def get_state(self):\n",
    "        return self.board.copy()\n",
    "    \n",
    "    def get_valid_actions(self):\n",
    "        return [(i, j) for i in range(3) for j in range(3) if self.board[i, j] == 0]\n",
    "    \n",
    "    def step(self, action):\n",
    "        i, j = action\n",
    "        if self.board[i, j] != 0:\n",
    "            raise ValueError(\"Invalid action: Cell is not empty\")\n",
    "            \n",
    "        self.board[i, j] = self.current_player\n",
    "        done, winner = self.is_done()\n",
    "        reward = self.get_reward(done, winner)\n",
    "        \n",
    "        self.current_player *= -1\n",
    "        return self.get_state(), reward, done, {\"Winner\": winner}\n",
    "    \n",
    "    def is_done(self):\n",
    "        for i in range(3):\n",
    "            if abs(sum(self.board[i, :])) == 3:\n",
    "                return True, np.sign(sum(self.board[i, :]))\n",
    "            if abs(sum(self.board[:, i])) == 3:\n",
    "                return True, np.sign(sum(self.board[:, i]))\n",
    "        if abs(sum([self.board[i, i] for i in range(3)])) == 3:\n",
    "            return True, np.sign(sum([self.board[i, i] for i in range(3)]))\n",
    "        if abs(sum([self.board[i, 2 - i] for i in range(3)])) == 3:\n",
    "            return True, np.sign(sum([self.board[i, 2 - i] for i in range(3)]))\n",
    "        \n",
    "        if not self.get_valid_actions():\n",
    "            return True, 0 # DRAW\n",
    "        \n",
    "        return False, None\n",
    "    \n",
    "    def get_reward(self, done, winner):\n",
    "        if not done:\n",
    "            return 0\n",
    "        if winner == 1:\n",
    "            return 1\n",
    "        elif winner == -1:\n",
    "            return -1\n",
    "        else:\n",
    "            return 0.5 # draw\n",
    "        \n",
    "    def render(self):\n",
    "        symbols = {1: 'X', -1: 'O', 0: '.'}\n",
    "        for row in self.board:\n",
    "            print(\" \".join(symbols[val] for val in row))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d38069",
   "metadata": {},
   "source": [
    "## Testing the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "892101aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . .\n",
      ". . .\n",
      ". . .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = TicTacToeEnv()\n",
    "\n",
    "state = env.reset()\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7149fc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player 1 plays (0, 2)\n",
      ". . X\n",
      ". . .\n",
      ". . .\n",
      "\n",
      "Player -1 plays (2, 1)\n",
      ". . X\n",
      ". . .\n",
      ". O .\n",
      "\n",
      "Player 1 plays (1, 2)\n",
      ". . X\n",
      ". . X\n",
      ". O .\n",
      "\n",
      "Player -1 plays (0, 0)\n",
      "O . X\n",
      ". . X\n",
      ". O .\n",
      "\n",
      "Player 1 plays (1, 1)\n",
      "O . X\n",
      ". X X\n",
      ". O .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    valid_actions = env.get_valid_actions()\n",
    "    action = random.choice(valid_actions)\n",
    "    print(f\"Player {env.current_player} plays {action}\")\n",
    "    \n",
    "    state, reward, done, info = env.step(action)\n",
    "    env.render()\n",
    "    \n",
    "    if done:\n",
    "        print(\"Game Over!\")\n",
    "        if info[\"winner\"] == 1:\n",
    "            print(\"X wins!\")\n",
    "        elif info[\"winner\"] == -1:\n",
    "            print(\"O wins!\")\n",
    "        else:\n",
    "            print(\"It's a draw!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8f4768c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . .\n",
      ". . .\n",
      ". . .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677f4d92",
   "metadata": {},
   "source": [
    "## Creating Gym Compatible Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5772e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicTacToeSelfPlayEnv(gym.Env):\n",
    "    def __init__(self, opponent_model=None):\n",
    "        super().__init__()\n",
    "        self.env = TicTacToeEnv()\n",
    "        self.opponent_model = opponent_model\n",
    "        \n",
    "        self.observation_space = spaces.Box(low=-1, high=1, shape=(3, 3), dtype=np.int8)\n",
    "        self.action_space = spaces.Discrete(9)\n",
    "        \n",
    "    def reset(self, *, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        obs = self.env.reset()\n",
    "\n",
    "        # If opponent goes first\n",
    "        if self.env.current_player == -1 and self.opponent_model:\n",
    "            obs = self._opponent_step(obs)\n",
    "\n",
    "        return self._get_obs(), {}\n",
    "    \n",
    "    def step(self, action_index):\n",
    "        valid_actions = self.env.get_valid_actions()\n",
    "        row, col = divmod(action_index, 3)\n",
    "        \n",
    "        if (row, col) not in valid_actions:\n",
    "            row, col = valid_actions[np.random.randint(len(valid_actions))]\n",
    "            \n",
    "        obs, reward, done, info = self.env.step((row, col))\n",
    "        \n",
    "        if done:\n",
    "            return self._get_obs(), reward, done, False, info\n",
    "        \n",
    "        if self.env.current_player == -1 and self.opponent_model:\n",
    "            obs = self._opponent_step(obs)\n",
    "\n",
    "            # Check if game ended after opponent played\n",
    "            done, winner = self.env.is_done()\n",
    "            reward = self.env.get_reward(done, winner)\n",
    "\n",
    "            info[\"winner\"] = winner\n",
    "            return self._get_obs(), reward, done, False, info\n",
    "\n",
    "        return self._get_obs(), 0.0, False, False, {}\n",
    "    \n",
    "    def _opponent_step(self, obs):\n",
    "        action, _ = self.opponent_model.predict(obs * -1)  # Flip for opponent's perspective\n",
    "        row, col = divmod(action, 3)\n",
    "        valid_actions = self.env.get_valid_actions()\n",
    "        if (row, col) not in valid_actions:\n",
    "            row, col = valid_actions[np.random.randint(len(valid_actions))]\n",
    "        self.env.step((row, col))\n",
    "        return self.env.get_state()\n",
    "\n",
    "    def _get_obs(self):\n",
    "        return self.env.get_state() * self.env.current_player  # Perspective-based obs\n",
    "\n",
    "    def render(self):\n",
    "        self.env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250148ef",
   "metadata": {},
   "source": [
    "## Logs saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03528b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"./ppo_logs\"\n",
    "model_dir = \"./saved_models\"\n",
    "os.makedirs(log_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c62d2237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./ppo_logs\\PPO_1\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 4.16     |\n",
      "|    ep_rew_mean     | 0.31     |\n",
      "| time/              |          |\n",
      "|    fps             | 961      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4.22         |\n",
      "|    ep_rew_mean          | 0.335        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 798          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070934896 |\n",
      "|    clip_fraction        | 0.0405       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.19        |\n",
      "|    explained_variance   | -0.22        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.276        |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0101      |\n",
      "|    value_loss           | 0.61         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.14        |\n",
      "|    ep_rew_mean          | 0.36        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 759         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009510048 |\n",
      "|    clip_fraction        | 0.0667      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.18       |\n",
      "|    explained_variance   | 0.0148      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.259       |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    value_loss           | 0.545       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.17        |\n",
      "|    ep_rew_mean          | 0.32        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 723         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010198312 |\n",
      "|    clip_fraction        | 0.0822      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.16       |\n",
      "|    explained_variance   | 0.0178      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.253       |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    value_loss           | 0.562       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.23        |\n",
      "|    ep_rew_mean          | 0.35        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 716         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009760278 |\n",
      "|    clip_fraction        | 0.082       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.15       |\n",
      "|    explained_variance   | 0.0246      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.208       |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    value_loss           | 0.558       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.18        |\n",
      "|    ep_rew_mean          | 0.545       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 708         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011406654 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.11       |\n",
      "|    explained_variance   | 0.0545      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.245       |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    value_loss           | 0.519       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.24        |\n",
      "|    ep_rew_mean          | 0.505       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 701         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010639942 |\n",
      "|    clip_fraction        | 0.0924      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.08       |\n",
      "|    explained_variance   | 0.00943     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.267       |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 0.505       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.08        |\n",
      "|    ep_rew_mean          | 0.58        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 691         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011459645 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.01       |\n",
      "|    explained_variance   | 0.0446      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.246       |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    value_loss           | 0.487       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.03        |\n",
      "|    ep_rew_mean          | 0.45        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 691         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008915979 |\n",
      "|    clip_fraction        | 0.0736      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.98       |\n",
      "|    explained_variance   | 0.0514      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.217       |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    value_loss           | 0.532       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.24       |\n",
      "|    ep_rew_mean          | 0.46       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 690        |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 29         |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01041366 |\n",
      "|    clip_fraction        | 0.117      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.92      |\n",
      "|    explained_variance   | 0.0704     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.252      |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.0182    |\n",
      "|    value_loss           | 0.471      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4.06         |\n",
      "|    ep_rew_mean          | 0.595        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 688          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 32           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0126979165 |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.87        |\n",
      "|    explained_variance   | 0.0708       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.269        |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.0171      |\n",
      "|    value_loss           | 0.493        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.07        |\n",
      "|    ep_rew_mean          | 0.49        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 689         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009954253 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.0346      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.216       |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 0.443       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.05        |\n",
      "|    ep_rew_mean          | 0.51        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 688         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011545761 |\n",
      "|    clip_fraction        | 0.0998      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.81       |\n",
      "|    explained_variance   | 0.0536      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.222       |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    value_loss           | 0.467       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.03        |\n",
      "|    ep_rew_mean          | 0.385       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 689         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008096756 |\n",
      "|    clip_fraction        | 0.0881      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.8        |\n",
      "|    explained_variance   | 0.0629      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.18        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    value_loss           | 0.437       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.09        |\n",
      "|    ep_rew_mean          | 0.45        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 690         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008745734 |\n",
      "|    clip_fraction        | 0.0835      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.79       |\n",
      "|    explained_variance   | 0.0902      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.201       |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    value_loss           | 0.473       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.16        |\n",
      "|    ep_rew_mean          | 0.615       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 686         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010656923 |\n",
      "|    clip_fraction        | 0.0872      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.72       |\n",
      "|    explained_variance   | 0.0702      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0973      |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 0.473       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.16        |\n",
      "|    ep_rew_mean          | 0.535       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 684         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009573689 |\n",
      "|    clip_fraction        | 0.0993      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | 0.0597      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.124       |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 0.363       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.09        |\n",
      "|    ep_rew_mean          | 0.64        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 681         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 54          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011168752 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.67       |\n",
      "|    explained_variance   | 0.0858      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.236       |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0195     |\n",
      "|    value_loss           | 0.397       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 3.96       |\n",
      "|    ep_rew_mean          | 0.605      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 681        |\n",
      "|    iterations           | 19         |\n",
      "|    time_elapsed         | 57         |\n",
      "|    total_timesteps      | 38912      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00963136 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.61      |\n",
      "|    explained_variance   | 0.0685     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.166      |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | -0.0156    |\n",
      "|    value_loss           | 0.364      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.01        |\n",
      "|    ep_rew_mean          | 0.715       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 681         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010270256 |\n",
      "|    clip_fraction        | 0.0855      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.57       |\n",
      "|    explained_variance   | 0.0537      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.177       |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 0.405       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.93        |\n",
      "|    ep_rew_mean          | 0.59        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 683         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 62          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009628574 |\n",
      "|    clip_fraction        | 0.0963      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.53       |\n",
      "|    explained_variance   | 0.0929      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.185       |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 0.357       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 3.9        |\n",
      "|    ep_rew_mean          | 0.79       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 680        |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 66         |\n",
      "|    total_timesteps      | 45056      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00989362 |\n",
      "|    clip_fraction        | 0.111      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.48      |\n",
      "|    explained_variance   | 0.0458     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.223      |\n",
      "|    n_updates            | 210        |\n",
      "|    policy_gradient_loss | -0.0183    |\n",
      "|    value_loss           | 0.343      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.94        |\n",
      "|    ep_rew_mean          | 0.705       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 680         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010337887 |\n",
      "|    clip_fraction        | 0.0951      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.44       |\n",
      "|    explained_variance   | 0.0663      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.164       |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 0.325       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.82        |\n",
      "|    ep_rew_mean          | 0.735       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 680         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 72          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011390744 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | 0.0786      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.131       |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    value_loss           | 0.307       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.96        |\n",
      "|    ep_rew_mean          | 0.76        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 681         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010287003 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.111       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.162       |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    value_loss           | 0.28        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.73        |\n",
      "|    ep_rew_mean          | 0.78        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 682         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 78          |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011420235 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.0769      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.1         |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0201     |\n",
      "|    value_loss           | 0.276       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.63        |\n",
      "|    ep_rew_mean          | 0.895       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 682         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 80          |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010582203 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.055       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0612      |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0181     |\n",
      "|    value_loss           | 0.258       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 3.81         |\n",
      "|    ep_rew_mean          | 0.79         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 683          |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 83           |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0112603735 |\n",
      "|    clip_fraction        | 0.129        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.15        |\n",
      "|    explained_variance   | 0.0955       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0713       |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.0213      |\n",
      "|    value_loss           | 0.259        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 3.7        |\n",
      "|    ep_rew_mean          | 0.83       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 684        |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 86         |\n",
      "|    total_timesteps      | 59392      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00893229 |\n",
      "|    clip_fraction        | 0.1        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.11      |\n",
      "|    explained_variance   | 0.0803     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0878     |\n",
      "|    n_updates            | 280        |\n",
      "|    policy_gradient_loss | -0.015     |\n",
      "|    value_loss           | 0.231      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.71        |\n",
      "|    ep_rew_mean          | 0.82        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 684         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 89          |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008296829 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.12       |\n",
      "|    explained_variance   | 0.0935      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0524      |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.63        |\n",
      "|    ep_rew_mean          | 0.83        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 685         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 92          |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009111259 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.0589      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0289      |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    value_loss           | 0.212       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.72        |\n",
      "|    ep_rew_mean          | 0.805       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 686         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 95          |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008706225 |\n",
      "|    clip_fraction        | 0.099       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.0985      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0519      |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    value_loss           | 0.181       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.5         |\n",
      "|    ep_rew_mean          | 0.92        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 686         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 98          |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009045349 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.0986      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0948      |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    value_loss           | 0.227       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.61        |\n",
      "|    ep_rew_mean          | 0.855       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 687         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 101         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007977829 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.972      |\n",
      "|    explained_variance   | 0.104       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0766      |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    value_loss           | 0.134       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.49        |\n",
      "|    ep_rew_mean          | 0.855       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 686         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 104         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008310143 |\n",
      "|    clip_fraction        | 0.0819      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.939      |\n",
      "|    explained_variance   | 0.0744      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0756      |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 0.156       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.55        |\n",
      "|    ep_rew_mean          | 0.875       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 687         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 107         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008935716 |\n",
      "|    clip_fraction        | 0.0947      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.909      |\n",
      "|    explained_variance   | 0.108       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0608      |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    value_loss           | 0.166       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 3.66      |\n",
      "|    ep_rew_mean          | 0.885     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 687       |\n",
      "|    iterations           | 37        |\n",
      "|    time_elapsed         | 110       |\n",
      "|    total_timesteps      | 75776     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0069261 |\n",
      "|    clip_fraction        | 0.0759    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.896    |\n",
      "|    explained_variance   | 0.126     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0413    |\n",
      "|    n_updates            | 360       |\n",
      "|    policy_gradient_loss | -0.0135   |\n",
      "|    value_loss           | 0.186     |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 3.57         |\n",
      "|    ep_rew_mean          | 0.81         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 688          |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 113          |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068713916 |\n",
      "|    clip_fraction        | 0.0814       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.877       |\n",
      "|    explained_variance   | 0.12         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.103        |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.0132      |\n",
      "|    value_loss           | 0.149        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.44        |\n",
      "|    ep_rew_mean          | 0.865       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 688         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 115         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010892568 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.852      |\n",
      "|    explained_variance   | 0.099       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0614      |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    value_loss           | 0.147       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 3.63         |\n",
      "|    ep_rew_mean          | 0.87         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 689          |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 118          |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073779617 |\n",
      "|    clip_fraction        | 0.0884       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.831       |\n",
      "|    explained_variance   | 0.0603       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0741       |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.0143      |\n",
      "|    value_loss           | 0.124        |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.47        |\n",
      "|    ep_rew_mean          | 0.94        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 689         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 121         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010001609 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.805      |\n",
      "|    explained_variance   | 0.0947      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.043       |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    value_loss           | 0.115       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 3.45         |\n",
      "|    ep_rew_mean          | 0.875        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 690          |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 124          |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064289654 |\n",
      "|    clip_fraction        | 0.0868       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.753       |\n",
      "|    explained_variance   | 0.0816       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0457       |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.0141      |\n",
      "|    value_loss           | 0.108        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.51        |\n",
      "|    ep_rew_mean          | 0.82        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 690         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 127         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008453143 |\n",
      "|    clip_fraction        | 0.0668      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.759      |\n",
      "|    explained_variance   | 0.128       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00833    |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    value_loss           | 0.119       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.48        |\n",
      "|    ep_rew_mean          | 0.92        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 691         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 130         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005539734 |\n",
      "|    clip_fraction        | 0.0678      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.724      |\n",
      "|    explained_variance   | 0.0793      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0429      |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 0.149       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 3.43         |\n",
      "|    ep_rew_mean          | 0.915        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 691          |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 133          |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061146202 |\n",
      "|    clip_fraction        | 0.0759       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.715       |\n",
      "|    explained_variance   | 0.108        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0732       |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.0135      |\n",
      "|    value_loss           | 0.115        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 3.45         |\n",
      "|    ep_rew_mean          | 0.915        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 692          |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 136          |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063462355 |\n",
      "|    clip_fraction        | 0.0685       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.689       |\n",
      "|    explained_variance   | 0.135        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0235       |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.0142      |\n",
      "|    value_loss           | 0.0702       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 3.38         |\n",
      "|    ep_rew_mean          | 0.93         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 692          |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 138          |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067601237 |\n",
      "|    clip_fraction        | 0.0765       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.644       |\n",
      "|    explained_variance   | 0.091        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0449       |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.0146      |\n",
      "|    value_loss           | 0.108        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.46        |\n",
      "|    ep_rew_mean          | 0.905       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 693         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 141         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007739907 |\n",
      "|    clip_fraction        | 0.089       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.644      |\n",
      "|    explained_variance   | 0.0886      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0421      |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 0.0994      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 3.37         |\n",
      "|    ep_rew_mean          | 0.935        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 693          |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 144          |\n",
      "|    total_timesteps      | 100352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063599665 |\n",
      "|    clip_fraction        | 0.0753       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.609       |\n",
      "|    explained_variance   | 0.0883       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00172     |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.0163      |\n",
      "|    value_loss           | 0.0772       |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x1a3e32c62d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opponent_model = PPO(\"MlpPolicy\", DummyVecEnv([lambda: TicTacToeSelfPlayEnv()]), verbose=0)\n",
    "\n",
    "env = TicTacToeSelfPlayEnv(opponent_model=opponent_model)\n",
    "monitored_env = Monitor(env, log_dir)\n",
    "\n",
    "checkpoint_callback = CheckpointCallback(save_freq=25000, save_path=model_dir, name_prefix=\"ppo_selfplay_model\")\n",
    "\n",
    "model = PPO(\"MlpPolicy\", monitored_env, verbose=1, tensorboard_log=log_dir)\n",
    "\n",
    "model.learn(total_timesteps=100_000, callback=checkpoint_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2898d95",
   "metadata": {},
   "source": [
    "## Testing against Humans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "accbcc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_against_model(model, env):\n",
    "    inner_env = env.envs[0].env  # unwrap the actual TicTacToeOpponentEnv\n",
    "    obs = env.reset()[0]         # unwrap observation\n",
    "    done = False\n",
    "\n",
    "    print(\"You are 'O' (represented by -1), model is 'X' (represented by 1)\")\n",
    "    print(\"Cell numbers:\\n1 | 2 | 3\\n4 | 5 | 6\\n7 | 8 | 9\\n\")\n",
    "\n",
    "    while not done:\n",
    "        if inner_env.current_player == -1:\n",
    "            # Human's turn\n",
    "            valid = inner_env.get_valid_actions()\n",
    "            inner_env.render()\n",
    "            print(f\"Valid moves: {[r * 3 + c + 1 for r, c in valid]}\")\n",
    "            while True:\n",
    "                try:\n",
    "                    move = int(input(\"Enter your move (1-9): \")) - 1\n",
    "                    action = (move // 3, move % 3)\n",
    "                    if action in valid:\n",
    "                        break\n",
    "                    print(\"Invalid move. Try again.\")\n",
    "                except ValueError:\n",
    "                    print(\"Please enter a number between 1 and 9.\")\n",
    "            obs, reward, done, _ = inner_env.step(action)\n",
    "        else:\n",
    "            action_flat, _ = model.predict(obs, deterministic=True)\n",
    "            action_flat = int(action_flat)\n",
    "            action = (action_flat // 3, action_flat % 3)\n",
    "            valid_actions = inner_env.get_valid_actions()\n",
    "\n",
    "            # Check validity\n",
    "            if action not in valid_actions:\n",
    "                # Fallback to a valid random action if invalid\n",
    "                print(\"Model chose invalid move, selecting random valid move.\")\n",
    "                action = random.choice(valid_actions)\n",
    "\n",
    "            obs, reward, done, _ = inner_env.step(action)\n",
    "\n",
    "\n",
    "    inner_env.render()\n",
    "    if reward == 1:\n",
    "        print(\"Model won!\")\n",
    "    elif reward == -1:\n",
    "        print(\"You won!\")\n",
    "    else:\n",
    "        print(\"It's a draw!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32161153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are 'O' (represented by -1), model is 'X' (represented by 1)\n",
      "Cell numbers:\n",
      "1 | 2 | 3\n",
      "4 | 5 | 6\n",
      "7 | 8 | 9\n",
      "\n",
      ". . .\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "Valid moves: [1, 2, 3, 4, 6, 7, 8, 9]\n",
      "Enter your move (1-9): 1\n",
      "O . X\n",
      ". X .\n",
      ". . .\n",
      "\n",
      "Valid moves: [2, 4, 6, 7, 8, 9]\n",
      "Enter your move (1-9): 7\n",
      "O . X\n",
      "X X .\n",
      "O . .\n",
      "\n",
      "Valid moves: [2, 6, 8, 9]\n",
      "Enter your move (1-9): 6\n",
      "Model chose invalid move, selecting random valid move.\n",
      "O X X\n",
      "X X O\n",
      "O . .\n",
      "\n",
      "Valid moves: [8, 9]\n",
      "Enter your move (1-9): 8\n",
      "Model chose invalid move, selecting random valid move.\n",
      "O X X\n",
      "X X O\n",
      "O O X\n",
      "\n",
      "It's a draw!\n"
     ]
    }
   ],
   "source": [
    "model = PPO.load(\"./saved_models/ppo_selfplay_model_100000_steps.zip\")\n",
    "\n",
    "opponent_env = TicTacToeSelfPlayEnv()\n",
    "vec_env = DummyVecEnv([lambda: opponent_env])\n",
    "\n",
    "play_against_model(model, vec_env)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
